/**
 * Reflektera Text Harness v1.1
 * Generator - Builds internal prompt and generates output via OpenAI
 */

import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
import { config } from './config.js';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);
const HARNESS_ROOT = path.resolve(__dirname, '..');

// Anti-clone guardrail text
const ANTI_CLONE_GUARDRAIL = `
VIKTIG REGEL:
Anv√§nd examples som inspiration f√∂r FORM och K√ÑNSLA.
√ÖTERANV√ÑND ALDRIG exakta fraser eller meningar fr√•n examples.
Parafrasera alltid. Skapa nytt.
Om du k√§nner igen en mening fr√•n examples - skriv om den helt.
`;

/**
 * Load style DNA for a specific profile
 */
function loadStyleDNA(profile) {
  const styleDnaPath = path.join(HARNESS_ROOT, 'style_dna.md');
  const content = fs.readFileSync(styleDnaPath, 'utf-8');
  
  // Extract the relevant profile section
  const profileHeader = profile === 'brev' ? '## Brev-profil' : '## Warm Provocation-profil';
  const nextHeader = profile === 'brev' ? '## Warm Provocation-profil' : null;
  
  const startIndex = content.indexOf(profileHeader);
  if (startIndex === -1) {
    throw new Error(`Profile ${profile} not found in style_dna.md`);
  }
  
  let endIndex = nextHeader ? content.indexOf(nextHeader) : content.length;
  if (endIndex === -1) endIndex = content.length;
  
  return content.substring(startIndex, endIndex).trim();
}

/**
 * Load examples for a specific profile
 */
function loadExamples(profile) {
  const examplesPath = path.join(HARNESS_ROOT, 'examples.md');
  const content = fs.readFileSync(examplesPath, 'utf-8');
  
  // Extract the relevant profile section
  const profileHeader = profile === 'brev' ? '## Brev-profil' : '## Warm Provocation-profil';
  const nextHeader = profile === 'brev' ? '## Warm Provocation-profil' : null;
  
  const startIndex = content.indexOf(profileHeader);
  if (startIndex === -1) {
    throw new Error(`Profile ${profile} not found in examples.md`);
  }
  
  let endIndex = nextHeader ? content.indexOf(nextHeader) : content.length;
  if (endIndex === -1) endIndex = content.length;
  
  return content.substring(startIndex, endIndex).trim();
}

/**
 * Build the internal prompt based on spec, style DNA, and examples
 */
function buildInternalPrompt(spec, styleDna, examples) {
  const { profile, topic, audience, user_input, constraints, controls } = spec;
  
  const prompt = `# UPPGIFT
Skriv ett LinkedIn-inl√§gg enligt profilen "${profile}".

# STIL-DNA (f√∂lj detta noggrant)
${styleDna}

# EXEMPEL-FRAGMENT (f√∂r inspiration, EJ kopiering)
${examples}

${ANTI_CLONE_GUARDRAIL}

# ANV√ÑNDARENS INPUT
√Ñmne: ${topic}
M√•lgrupp: ${audience}
Beskrivning: ${user_input}

# CONSTRAINTS
- Spr√•k: ${constraints.language || 'sv'}
- L√§ngd: ${constraints.min_chars || 600}-${constraints.max_chars || 1200} tecken
- Inga asterisker (*) f√∂r formatering
- Signatur: /${constraints.signature?.name || 'F√∂rfattaren'}
  ${constraints.signature?.tagline || ''}

# KONTROLLER
- Friktion: ${controls?.friction || 3}/5 (hur mycket texten utmanar l√§saren)
- V√§rme: ${controls?.warmth || 3}/5 (hur varm/empatisk tonen √§r)
- Ber√§ttelse: ${controls?.story || 3}/5 (hur mycket personlig historia)

# OUTPUT
Skriv ENDAST LinkedIn-inl√§gget. Ingen inledning, ingen f√∂rklaring.
B√∂rja direkt med texten och avsluta med signaturen.
`;

  return prompt;
}

/**
 * Generate dummy output when API key is missing
 */
function generateDummyOutput(spec) {
  const { profile, constraints } = spec;
  
  if (profile === 'brev') {
    return `Du som sitter d√§r med datorn i kn√§t och oron i magen.
Du som f√∂rs√∂ker vara p√• tv√• st√§llen samtidigt.

Jag har varit du.
Jag minns k√§nslan n√§r telefonen ringde fr√•n f√∂rskolan.
Hur hj√§rtat sj√∂nk. Inte f√∂r att barnet var sjukt.
Utan f√∂r att jag visste vad det betydde f√∂r jobbet.

Det √§r ingen bra k√§nsla.
Att vara delad.

Men vet du vad?
Ditt barn kommer inte minnas vilka m√∂ten du missade.
De kommer minnas att du var d√§r.
I soffan. Med filmen. Med febriga kinder mot din axel.

Det √§r inte ett misslyckande.
Det √§r livet.

Du g√∂r det b√§sta du kan.
Och det √§r nog.

/${constraints.signature?.name || 'Ann-Christin'}
${constraints.signature?.tagline || ''}

[DUMMY OUTPUT - Genererat utan API-nyckel f√∂r testning]`;
  }
  
  // warm_provocation
  return `Du √§r inte konfliktr√§dd.
Du √§r konfliktointresserad.

Du vill ha harmoni ‚Äì men utan att betala f√∂r den.

S√• ist√§llet f√∂r att ta det d√§r samtalet:
‚Äì Du skriver ett "sn√§llt" DM ist√§llet f√∂r att ringa.
‚Äì Du nickar i m√∂tet men ventilerar i korridoren.
‚Äì Du s√§ger "vi tar det sen" och menar "aldrig".

Nej nej. Inte du.
Du "gillar bara inte on√∂digt drama".

Exakt.

Det √§r som att s√§ga att man √§lskar att tr√§na ‚Äì men bara i teorin.

Konflikter √§r inte sammanbrottet.
De √§r samtalet som aldrig fick h√§nda.

S√• n√§sta g√•ng du k√§nner den d√§r klumpen:
Ta samtalet. Inte DM:et.

/${constraints.signature?.name || 'Ann-Christin'}
${constraints.signature?.tagline || ''}

[DUMMY OUTPUT - Genererat utan API-nyckel f√∂r testning]`;
}

/**
 * Call OpenAI API to generate output
 */
async function callOpenAI(prompt, spec) {
  // Check if LLM is disabled
  if (!config.LLM_ENABLED) {
    console.log(`‚ö†Ô∏è  LLM disabled: ${config.LLM_SKIP_REASON}`);
    console.log('üìù Creating placeholder output...');
    return {
      output: generateDummyOutput(spec),
      isDummy: true,
      skipReason: config.LLM_SKIP_REASON
    };
  }
  
  const apiKey = process.env.OPENAI_API_KEY;
  
  if (!apiKey) {
    console.log('‚ö†Ô∏è  OPENAI_API_KEY saknas - genererar dummy output f√∂r testning');
    return {
      output: generateDummyOutput(spec),
      isDummy: true
    };
  }
  
  try {
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`
      },
      body: JSON.stringify({
        model: 'gpt-4o-mini',
        messages: [
          { role: 'system', content: 'Du √§r en expert p√• att skriva engagerande LinkedIn-inl√§gg p√• svenska. Du f√∂ljer instruktioner exakt.' },
          { role: 'user', content: prompt }
        ],
        temperature: 0.7,
        seed: spec.controls?.seed || undefined
      })
    });
    
    if (!response.ok) {
      const error = await response.json();
      throw new Error(`OpenAI API error: ${error.error?.message || response.statusText}`);
    }
    
    const data = await response.json();
    return {
      output: data.choices[0].message.content,
      isDummy: false,
      usage: data.usage
    };
  } catch (error) {
    console.error('‚ùå OpenAI API fel:', error.message);
    console.log('‚ö†Ô∏è  Faller tillbaka p√• dummy output');
    return {
      output: generateDummyOutput(spec),
      isDummy: true,
      error: error.message
    };
  }
}

/**
 * Main generate function
 */
export async function generate(specPath, runDir) {
  console.log('üìù L√§ser spec...');
  const spec = JSON.parse(fs.readFileSync(specPath, 'utf-8'));
  
  console.log(`üìÇ Profil: ${spec.profile}`);
  console.log(`üìÇ √Ñmne: ${spec.topic}`);
  
  // Load style DNA and examples
  console.log('üìö Laddar style DNA och examples...');
  const styleDna = loadStyleDNA(spec.profile);
  const examples = loadExamples(spec.profile);
  
  // Build internal prompt
  console.log('üîß Bygger internal prompt...');
  const internalPrompt = buildInternalPrompt(spec, styleDna, examples);
  
  // Save spec snapshot
  const specSnapshot = path.join(runDir, 'post_spec.json');
  fs.writeFileSync(specSnapshot, JSON.stringify(spec, null, 2));
  console.log(`üíæ Sparade: ${specSnapshot}`);
  
  // Save internal prompt
  const promptPath = path.join(runDir, 'internal_prompt_v1.txt');
  fs.writeFileSync(promptPath, internalPrompt);
  console.log(`üíæ Sparade: ${promptPath}`);
  
  // Generate output
  if (!config.LLM_ENABLED) {
    console.log('ü§ñ LLM disabled - creating placeholder output...');
  } else {
    console.log('ü§ñ Genererar output...');
  }
  
  const result = await callOpenAI(internalPrompt, spec);
  
  // Save output
  const outputPath = path.join(runDir, 'output_v1.txt');
  
  // If LLM was disabled, add clear marker to output
  let outputToSave = result.output;
  if (!config.LLM_ENABLED) {
    outputToSave = `[GENERATION SKIPPED - LLM DISABLED]\n\n${config.LLM_SKIP_REASON}\n\n---\n\n${outputToSave}`;
  }
  
  fs.writeFileSync(outputPath, outputToSave);
  console.log(`üíæ Sparade: ${outputPath}`);
  
  if (result.isDummy || !config.LLM_ENABLED) {
    if (!config.LLM_ENABLED) {
      console.log(`‚ö†Ô∏è  Placeholder output genererat (${config.LLM_SKIP_REASON})`);
    } else {
      console.log('‚ö†Ô∏è  Dummy output genererat (s√§tt OPENAI_API_KEY f√∂r riktigt output)');
    }
  } else {
    console.log(`‚úÖ Output genererat (${result.usage?.total_tokens || '?'} tokens)`);
  }
  
  return {
    spec,
    internalPrompt,
    output: result.output,
    isDummy: result.isDummy,
    runDir
  };
}

